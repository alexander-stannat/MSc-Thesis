\documentclass[11pt,a4paper]{article}
\usepackage{verbatim}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}
\usepackage{latexsym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\pagestyle{plain}
\pagenumbering{arabic}
\usepackage[margin=0.5cm]{geometry}
\topmargin -1cm
\textheight 25cm
\textwidth 16.0 cm
\oddsidemargin 0.2cm

\graphicspath{ {C:\Users\alexa\Documents\TU Delft\Course material\4.Semester\Master Thesis\Thesis} }


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}[section]

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}
\pagenumbering{gobble}
\bigskip\noindent
%\hrule\vspace{1em}
\begin{center}{\bf{\large \textsc{Cooperation and Evolutionary Game Theory in Distributed Computing}}}\end{center}\vspace{1em}
%\hrule
%\bigskip\bigskip\bigskip\noindent 
\begin{center}
{\Large Alexander Stannat} \vspace{3em}\\
%\includegraphics[scale=0.6]{"TU Delft Logo".png}
%\bigskip\bigskip \\ 
01.05.2019
\end{center}

%\setcounter{tocdepth}{2}
%\tableofcontents

\pagenumbering{arabic}
\section{The Evolution of Cooperation}
\label{sec:The Evolution of Cooperation}
Honest cooperation in a population is a requirement for any level of organisation to be reliably reached. From genes, unicellular organisms, and multicellular organisms to insect colonies and human societies, the ability to cooperate is of vital importance for the survival of these species. Interactions between agents in a population can be viewed as instances of evolutionary game theory. Each interaction places two agents together whereby one agent needs the other to contribute some resource to them. This is an altruistic act of the individual, but a requirement for the survival of the entire population. It should be noted that the concept of a resource is defined in an abstract sense here. This could be any kind of helpful act that contributes to the chance for survival of a peer.\vspace{1em}\\

\noindent{}Natural selection, however engenders competition among agents in a population such that selfish behaviour is rewarded. This can lead to a dilemma, commonly known as the "tragedy of the commons", in which the incentives of the individual are not aligned with those of the population as a collective. Such a dilemma is partially thwarted by the evolution of a number of mechanisms that induce cooperation in a population. Without any mechanism for the evolution of cooperation, natural selection favors defectors, which consequently outlive honest agents until there are only defectors left. \cite{5 Rules for the Evolution of Cooperation} introduced 5 of these, namely {\it kin selection}, {\it direct reciprocity}, {\it indirect reciprocity}, {\it network reciprocity} and {\it group selection}. The idea behind these particular mechanisms is to reward behaviour of individuals that is beneficial to members of the population other than themselves. \vspace{1em}\\

\noindent{}Out of all biological species there are on this planet, the human race has developped the by far most sophisticated and effective mechanism to facilitate cooperation across its entire population; Language. While many other life forms on earth have developed ways of communicating with one another, humans have developed the most intricate and complex method of communication. This is the reason that from an evolutionary perspective, we have arguably outdone all other biological species on this planet. Language enables humans to {\it gossip} about one another. While this might not initially seem like a significant contributor to reproductive success, it allows humans to share information about the trustworthiness of their peers and the likelihood that an individual will act cooperatively in the future. Humans have implemented the most successful type of indirect reciprocity through a simple reputation mechanism. \vspace{1em}\\

\noindent{}This reputation mechanism rewards altruistic behaviour and punishes uncooperative acts. If, in an interaction with a peer an agent decides to defect then that peer will spread information about the agent's defection and if said agent has another interaction with a new peer that knows about its defection then the agent is less likely to be collaborated with. Humans have developed an awareness of their own reputation over time which prompts them to behave cooperatively most of the time. Even with strangers whose reputation they might not even know, humans often act politely and considerately, due to this awareness. While kin selection and direct reciprocity can ensure the cooperation of smaller tribes and families, reputation is a key element in the functioning of large-scale societies. \vspace{1em}\\

\section{Reputation and Behaviour on the Internet}
\label{sec:Reputation and Behaviour on the Internet}
\noindent{}With the advent of one of the most disruptive technological revolutions in human history, namely the internet, humans have been given an entirely new platform to interact on globally. There are a wide variety of different networks in which different types of resources are shared, from P2P file sharing networks, where agents up- and download data to one another to social networks where humans interact by sharing content with one another and rewarding or chastising it with "likes" or "retweets", etc. The social graph of human interaction has changed significantly with the help of these tools.\vspace{1em}\\

\noindent{}On the internet humans no longer interact face-to-face and, more importantly, no longer need to disclose their identity to one another. Identity, however is indispensable for reputation. When humans have the ability to hide their identity behind one or several pseudonyms, they can defect without having to face any long-term repercussions. For a reputation mechanism to be effective identities need to be permanent and unique. This has caused a discrepancy between how humans interact in real life and on the internet. The regular mechanisms for cooperation no longer work and a new online analogue to reputation might have to be devised. This problem becomes particularly apparent in P2P networks.\vspace{1em}\\

\noindent{}The {\it Distributed Systems Group} at Delft University is running and developing a P2P file-sharing network, called {\it Tribler}, in which members can exchange and share files with one another. The idea is that, instead of users querying a central server that supplies the network, users exchange files among themselves through acts of {\it seeding} and {\it leeching}. Seeding is the act of distributing a piece of a file to another peer, while receiving a piece of data is called leeching. In most online networks with some kind of central authority, such as Ebay, Airbnb, etc. cooperativeness is achieved through review mechanisms, which are maintained and secured by the central authority. Agents can evaluate the trustworthiness of their interaction partners, by assessing their previous transactions and other agents' opinions of them.\vspace{1em}\\ 

\noindent{}Tribler, on the other hand, is decentralised, which means that there is no central authority that collects all information. An advantage of such decentralisation is the elimination of a single point of failure. The system is therefore more robust and resistant to attacks. However, coordinating distributed systems becomes challenging as there is no central authority that can make decisions on behalf of the network. Distributing a particular file to several peers, and deciding who gets to receive how much and when can become a rather sophisticated problem. The performance of this system highly depends on the availability of files, which is determined by agent's willingness to donate some bandwidth to their peers. While these types of systems have many advantages over the standard client-server model, they do have one fundamental problem: users have an obvious incentive to download, i.e. to leech, but no inherent incentive to seed. This results in behavior called lazy freeriding. \vspace{1em}\\

\noindent{}Different file sharing platforms have different mechanisms to enforce the necessary altruistic sharing of files. The most prominent P2P network, BitTorrent, employs a mechanism called {\it tit-for-tat}, which is an instance of direct reciprocity. Tit-for-tat is a highly effective strategy in game theory for the iterated prisoner's dilemma, in which an agent cooperates first and then replicates it's contender's previous actions. In practice, this works as follows. Peers in the BitTorrent network have a limited number of upload slots to allocate. An agent will begin by exchanging upload bandwidth for download bandwidth with a number of its peers. If one of these peers turns out to be a leecher, i.e. does not reciprocate, it will be choked out. This means the agent will discontinue it's cooperation and assign the corresponding upload slot to another randomly chosen peer in a procedure known as {\it optimistic unchoking}. \vspace{1em}\\

\noindent{}However, we find that in the case of fleeting and asymmetric interactions, tit-for-tat is no longer very effective \cite{A Simple Rule for the Evolution of Cooperation on Graphs and Social Networks}. Fleeting and asymmetric means that agents have many unrepeated and short-term interactions with their peers. When there is a high probability of two agents not seeing each other again, defecting becomes the dominant strategy in the Prisoner's dilemma \cite{An optimal strategy to solve the prisoner's dilemma}. The agents' inability to coordinate and build expectations of their counterparts ensures that everyone will be worse off than if they had collaborated, but no individual can gain anything by changing to a collaborate strategy. This is what we referred to as the tragedy of the commons earlier. In tit-for-tat agents do not keep a memory about their peer’s reliability which enables such lazy freeriding and other types of uncooperative behaviour. There is no mechanism with which peers can be evaluated based on their previous reliability and hence every new transaction entails the risk of the contender defecting. \vspace{1em}\\

\noindent{}In an attempt to alleviate the problem of freeriding, Tribler aims to leverage the power of social phenomena such as indirect reciprocity and group selection, in an attempt to facilitate a more reliable filesharing platform. Agents gossip about their transaction partners and inform others about their respective trustworthiness. From this information agents can aggregate an approximation of a particular peer's reputation in the network. An agent that holds parts of a particular file will receive queries from peers that require that particular file. The agent holding the file will then decide whom to upload to, based on the reputation of those in the queue. After having some work performed the reputation of the performer will increase while that of the recipient will decrease, such that in the next interaction the peer that has performed the work will have a higher probability of receiving work and the recipient will have a lower one. \vspace{1em}\\

\begin{comment}
\section{Mechanisms for Social Cooperation}
\label{sec:Mechanisms for Social Cooperation}
Nowak M.A. in \cite{5 Rules for the Evolution of Cooperation} identifies 5 rules for the evolution of cooperation:
\begin{itemize}
\item Kin selection: Natural selection can favour cooperation if contributer and beneficiary are genetic relatives. Such an act is beneficial if the cost-to-benefit ratio exceeds the factor of relatedness.
\item Direct Reciprocity: In the case of repeated encounters between the same individuals with consecutive rounds of interactions, an agent will decide whether to cooperate based on its contender's previous action. This is the aforementioned tit-for-tat strategy, which in the case of file-sharing networks does not work. Another strategy based on direct reciprocity is called win-stay, lose-shift, whereby an agent decides to keep up their current strategy as long as it works and, else decides to change to the other strategy. Direct reciprocity leads to global cooperation is the cost-to-benefit ratio is exceeded by the probability of another interaction between the same agents
\item Indirect Reciprocity: While direct reciprocity resembles a barter economy, indirect reciprocity is similar to money. It works on the basis of reputation. Agents may not have the chance to reciprocate directly. Instead, people contribute to the community on the assumption that it will increase their reputation, which in turn increases the probability of them receiving some work. This mechanism only induces cooperation if the probability of knowing someone's reputation exceeds the cost-to-benefit ratio of the interaction.
\item Network Reciprocity: We can picture this best in a graph-theoretic setting, in which every agent pays a cost for all of their neighbours in the graph to receive a benefit. If they defect then their neighbours don't receive a benefit. Cooperators can prevail by forming network clusters among themselves, by only interacting with cooperators. This rule leads to cooperation if benefit-to-cost ratio exceeds the average number of neighbours each node has. 
\item Group Selection: The network is subdivided into groups and these groups grow as offspring is produced. As a group reaches a certain size  it splits in two and another group is eliminated. We find that defectors in a mixed group proliferate faster than honest nodes. However, groups consisting of only honest nodes split much faster than mixed groups or groups with only defectors. Hence honest groups soon dominate the network. This only happens provided that the benefit-to-cost ratio is greater than the ratio of all nodes to number of groups plus 1.
\end{itemize}
\end{comment}


\section{Sybil Attacks and Misreports}
\label{sec:Sybil Attacks and Misreports}
A reputation mechanism is meant to prevent lazy freeriding by punishing defectors with a bad rating. However, there are ways for bad actors to cover up their misbehaviour and exploit the network structure to leech excessively without being punished by the reputation mechanism. The two most prominent ways for doing this are {\it sybil attacks} and {\it misreporting attacks}. \vspace{1em}\\

\noindent{}A sybil attack occurs when a large number of identities are generated that are all brought into existence and controlled by a single malicious agent. This agent will then attempt to exploit the control he or she has in order to artificially increase the reputation score of one or more of these identities by reporting high levels of reputability without actually performing any work. This can be done because Sybil identities can create forged reports about one another. Such attacks can have strongly detrimental effects on the functioning of P2P networks. \vspace{1em}\\

\noindent{}Since there is no central server that holds and processes all information in the network, agents have to rely on reports by their peers. This, of course can be exploited by malicious actors that may decide to manipulate certain agents' perception of the network activity in an attempt to increase their own reputability or discredit their peers.  

\section{Thesis Goal}
\label{sec:Thesis Goal}
In this thesis project it is our goal to draw on mechanisms of cooperation that evolve in nature, primarily indirect reciprocity and apply it to the context of P2P networks. We aim to devise a mathematical algorithm which exploits structural aspects of the social graph to determine which agents are cooperators and which aren't. Especially important is that the algorithm be resistant to sybil and misreport attacks. Our algorithm should be able to satisfy the two conditions of what \cite{How Should We Define Goodness} identify as the {\it leading eight}: Cooperation with reputable people and defection against disreputable people should lead to an increase in reputation score, doing the opposite should reduce one's reputation. The algorithm should satisfy the requirement for transitvity as well. This means, that if reports of reputability should be weighted according to the reputability of the agent doing the report. Ideally, we'd try to construct an algorithm that covers a large number of P2P social networks, ranging from social media networks to file-sharing communities. Our main focus, however will lie on the Tribler application.\vspace{1em}\\ 

\noindent{}

\section{Related Work}
\label{sec:Related Work}
There have been a number of attempts at implementing such an algorithm in the past. In \cite{A Random Walk Based Trust Ranking in Distributed Systems} we attempted to derive a personalised reputation mechanism from the random walk based pagerank algorithm \cite{PageRank}. The idea was to have every node in the network run a number of random walks along their outgoing edges and the number of times these random walks crossed a particular node would then determine their trustworthiness. While this certainly was a computationally feasible solution, it was difficult to find a way to make it resistant to Sybil attacks. In \cite{BarterCast} the authors devised an algorithm that would determine an agent's reputability based on their contribution made to another node by determining the maximum flow from the source node to the target node along the edges of the social graph. However, BarterCast proved not Sybil resistant at all. In \cite{NetFlow} the authors constructed an accounting mechanism which is based on the aforementioned BarterCast mechanism capped at the net contribution to the network of each agent.  



\begin{thebibliography}{9}
\bibitem{NetFlow}
Buechler, Matthew, et al. Decentralized reputation system for transaction networks. Technical report, University of Pennsylvania, 2015.
\bibitem{BarterCast}
Meulpolder, Michel, et al. "Bartercast: A practical approach to prevent lazy freeriding in p2p networks." 2009 IEEE International Symposium on Parallel \& Distributed Processing. IEEE, 2009.
\bibitem{An Optimal Strategy to Solve the Prisoner's Dilemma}
Bravetti, Alessandro, and Pablo Padilla. "An optimal strategy to solve the Prisoner’s Dilemma." Scientific reports 8.1 (2018): 1948.
\bibitem{5 Rules for the Evolution of Cooperation}
Nowak, Martin A. "Five rules for the evolution of cooperation." science 314.5805 (2006): 1560-1563.
\bibitem{A Simple Rule for the Evolution of Cooperation on Graphs and Social Networks}
Ohtsuki, Hisashi, et al. "A simple rule for the evolution of cooperation on graphs and social networks." Nature 441.7092 (2006): 502.
\bibitem{How Should We Define Goodness}
Ohtsuki, Hisashi, and Yoh Iwasa. "How should we define goodness?—reputation dynamics in indirect reciprocity." Journal of theoretical biology 231.1 (2004): 107-120.
\bibitem{PageRank}
Page, Lawrence, et al. The PageRank citation ranking: Bringing order to the web. Stanford InfoLab, 1999. 
\bibitem{A Random Walk Based Trust Ranking in Distributed Systems}
Stannat, Alexander, and Johan Pouwelse. "A Random Walk based Trust Ranking in Distributed Systems." arXiv preprint arXiv:1903.05900 (2019).
\end{thebibliography}
\end{document}